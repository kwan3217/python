{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Mathematicians think [the Gaussian distribution] is a law of nature and physicists are convinced it is a mathematical theorem.\n",
    " > -- Gabriel Lippman, from Grewal and Andrews p62\n",
    " \n",
    "Given a mean and covariance matrix, you can generate a random population that (approximately) fits it and you can draw ellipsoids of given standard deviation. Likewise, given a set of samples presumed to be drawn from a Gaussian distribution, you can determine the mean and covariance.\n",
    "\n",
    "Any Gaussian normal multivariate distribution of a random variable $\\vec{X}$ is described by a mean vector $\\bar{x}$ and a covariance matrix $\\M{P}$. The mean vector is exactly what it seems. The covariance matrix is a property of a random vector variable and is defined as:\n",
    "\n",
    "$$\\M{P}=\\operatorname E((\\vec{X}-\\bar{x})(\\vec{X}-\\bar{x})^T)$$\n",
    "\n",
    "The scalar variance is the square of the standard deviation and has units of the square of the units of the scalar variable. Likewise the covariance matrix is the \"square\" of what you might think of as the standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a sample set from a mean and covariance\n",
    "The following recipe is underived here.\n",
    "\n",
    "* Generate a sample set with the required number of vectors $N$ with the required number of components $m$, each a sample of a Gaussian normal scalar random variable with zero mean and variance 1. This will create a set of vectors with (approximately) zero vector mean and covariance equal to the $m \\times m$ identity matrix. We will consider this to be a matrix $\\M{X}$, where each sample is a column vector, therefore the matrix has size $m\\times N$.\n",
    "* Calculate the lower Cholesky decomposition of the covariance matrix $\\M{A}=\\operatorname{chol}(\\M{P})$.\n",
    "* You can check by verifying that $\\M{A}\\M{A}^T=\\M{P}$ to sufficient precision\n",
    "* Use the $\\M A$ matrix to transform the set of vectors, giving a set $\\M{Y}=\\M{A}\\M{X}$ with zero mean and the given covariance $\\M{P}$.\n",
    "* Add the mean vector $\\bar{x}$ to each column generating a new matrix $\\M{Z}$ such that $\\vec{Z}_{\\operatorname{column}i}=\\vec{Y}_{\\operatorname{column}i}+\\bar{x}$. This $\\M{Z}$ is the desired sample, with given mean $\\bar{x}$ and covariance about that mean $\\M{P}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from numpy.linalg import cholesky\n",
    "\n",
    "def pnoise(N,P,xbar=None):\n",
    "    m=P.shape[0]\n",
    "    X=nr.randn(m,N)\n",
    "    A=cholesky(P)\n",
    "    X=A@X\n",
    "    if xbar is not None:\n",
    "        X+=xbar\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing uncertainty ellipsoids \n",
    "Often it is educational to draw ellipsoids of one or more \"$n$-sigma\" surfaces. We can use the same matrix $\\M{A}$ from above. This time, the samples will not be taken at random, but will be a circle of radius $n$ and the required dimension. For instance, a 2-element vector random variable will require an $S_1$ (just a normal circle) in 2D space, a 3-element vector an $S_2$ circle (surface of a sphere) in 3D space, a 4-element vector is a $S_3$ (surface of a 4D hypersphere) in 4D space, and in general an $n$-element vector will require a set of samples of distance $n$ from the origin of $n$-space, or a unit-radius $S_{n-1}$.\n",
    "\n",
    "Code for the 2D case follows. Higher dimensions are harder simply because it is harder to evenly space points on the surface of a sphere or hypersphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pell(n,P,xbar=None):\n",
    "    q=np.arange(0,2*np.pi,0.01)\n",
    "    c=np.cos(q)\n",
    "    s=np.sin(q)\n",
    "    X=np.array([c,s])*n \n",
    "    A=cholesky(P)\n",
    "    X=A @ X\n",
    "    if xbar is not None:\n",
    "        X+=xbar\n",
    "    return X\n",
    "\n",
    "P=np.array([[3,3],[3,4]])\n",
    "xbar=np.array([[100],[-200]])\n",
    "x=pnoise(1000,P,xbar)\n",
    "e1=pell(1,P,xbar)\n",
    "e2=pell(2,P,xbar)\n",
    "e3=pell(3,P,xbar)\n",
    "plt.figure(\"Covariance\")\n",
    "plt.plot(x [0,:],x [1,:],'k.')\n",
    "plt.plot(e1[0,:],e1[1,:],'r-')\n",
    "plt.plot(e2[0,:],e2[1,:],'g-')\n",
    "plt.plot(e3[0,:],e3[1,:],'b-')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating covariance given a set of samples\n",
    "The mean is easy, it's just the total of all the vectors divided by the number of vectors\n",
    "\n",
    "The covariance is calculated as:\n",
    "\n",
    "$$\\M{P} = \\frac{1}{m-1}\\sum_{i=1}^m (\\vec{x}_i-\\bar{x})(\\vec{x}_i-\\bar{x})^T$$\n",
    "\n",
    "We are using $\\frac{1}{N-1}$ for the same reason we use it in a sample standard deviation -- there is one less degree of freedom due to the fact that we have to calculate the mean from the samples as well as the standard deviation.\n",
    "\n",
    "Alternatively, arranging the observation vectors as the columns of a matrix, so that\n",
    "\n",
    "$$\\M{X} = \\begin{bmatrix}\\vec{x}_1 & \\vec{x}_2 & \\dots & \\vec{x}_N \\end{bmatrix}$$\n",
    "\n",
    "which is a matrix of $m$ rows and $N$ columns. Then, the sample covariance matrix can be computed as\n",
    "\n",
    "$$\\M{P} = \\frac{1}{N-1}\\left( \\M{F} - \\bar{x}\\vec{1}^T \\right)\\left( \\M{F} - \\bar{x}\\vec{1}^T\\right)^T$$\n",
    "\n",
    "where $\\vec{1}$ is a column vector with all components 1. This is used to create an $m \\times N$ matrix where every column vector is $\\bar{x}$. In code we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcalc(X):\n",
    "    xbar=np.mean(X,1).reshape(-1,1)\n",
    "    Xac=X - xbar\n",
    "    N=Xac.shape[1]\n",
    "    P=(Xac @ Xac.T)/(N-1)\n",
    "    return (xbar,P)\n",
    "\n",
    "print(pcalc(x))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
