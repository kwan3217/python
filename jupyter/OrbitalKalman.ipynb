{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orbital motion\n",
    "Now we will start on the problem that the Kalman filter was most famously first used for (and the context where I learned it): Orbital motion.\n",
    "    \n",
    "$$\n",
    "\\def\\M#1{{[\\mathbf{#1}]}}\n",
    "\\def\\MM#1#2{{[\\mathbf{#1}{#2}]}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def _inv(x):\n",
    "    \"\"\"\n",
    "    Matrix inverse which also handles scalars properly\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return inv(x)\n",
    "    except ValueError:\n",
    "        return np.array([[1.0/x]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition\n",
    "\n",
    "This is the simplest form of the orbit determination problem I learned this filter on back in school. A satellite is in orbit around a point mass. Newton's gravitation applies. The satellite is tracked from a radar at a fixed point above the point mass (or on the surface of a perfectly smooth, homogeneous, radar-transparent planet) in the plane of the satellite orbit. The point mass is so much heavier than the satellite that we may treat the satellite as a test mass. This means that the gravity of the satellite does not significantly move the central mass, and therefore the mass of the satellite cancels right out of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Vector\n",
    "\n",
    "This is like the cart, but now we have two dimensions. It is provable that the trajectory of any test mass around a point mass is confined to a plane containing the point mass, as long as it is only under the influence of gravity, or if all other forces are in the plane also.\n",
    "\n",
    "\n",
    "So, our state vector has four components, two for position and two for velocity, for a total of four.\n",
    "\n",
    "$$\n",
    "\\vec{x}=\\begin{bmatrix}r_x \\\\ r_y \\\\ v_x \\\\ v_y\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We are using $r$ instead of $p$ for position, mostly for historical reasons. Think of it as the \"ray\" or \"radius\" from the center of mass to the satellite. The names of the components suggest that we can have:\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\vec{r}&=&\\begin{bmatrix}r_x \\\\ r_y\\end{bmatrix}\\\\\n",
    "\\vec{v}&=&\\begin{bmatrix}v_x \\\\ v_y\\end{bmatrix}\\\\\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "We may use this notation when appropriate, meaning that the whole state is the concatenation of these two vectors:\n",
    "\n",
    "$$\n",
    "\\vec{x}=\\begin{bmatrix}\\vec{r} \\\\ - \\\\ \\vec{v}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics\n",
    "\n",
    "This time we use Newton's Universal Law of Gravitation (in title caps, because it is important.)\n",
    "\n",
    "$$F=\\frac{GMm}{r^2}$$\n",
    "\n",
    "This is combined with Newton's second law:\n",
    "\n",
    "$$F=ma$$\n",
    "\n",
    "to get:\n",
    "\n",
    "$$ma=\\frac{GMm}{r^2}$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $F$ is the magnitude of the force on the test mass (only used in this section, above this point, a few times, not to be confused with function $F(\\vec{x})$ which is used to describe the rate of change of the state vector).\n",
    "* $G$ is the universal gravitational constant\n",
    "* $M$ is the mass of the central mass\n",
    "* $m$ is the mass of the test mass, $m<<M$\n",
    "* $r=\\sqrt{r_x^2+r_y^2}$ is the distance from the central mass to the test mass\n",
    "* $a$ is the magnitude of the acceleration imposed on the test mass\n",
    "\n",
    "We see that m appears on both sides, so we will cancel it out and get:\n",
    "\n",
    "$$a=\\frac{GM}{r^2}$$\n",
    "\n",
    "Also, this is a vector acceleration, directed towards the center of mass, so multiply this by a unit vector pointing from the test mass to the center $-\\vec{r}/r$ to get\n",
    "\n",
    "$$\\vec{a}=\\frac{-GM\\vec{r}}{r^3}$$\n",
    "\n",
    "It is very difficult to measure $G$ by itself, as this involves measuring gravity exerted by objects small enough to fit in a laboratory. It is also very difficult to measure $M$ of a planet by itself, because it's a whole planet, and won't fit on a scale. However, by observing the motions of satellites, it turns out that it is easy to accurately measure the product $GM$ much more accurately than either $G$ or $M$. So, we call this product $\\mu$ (Greek small mu) and use it instead.\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "F(\\vec{x})&=&\\vec a \\\\\n",
    "                &=&\\frac{-\\mu\\vec r}{r^3}\n",
    "                \\end{eqnarray*}$$\n",
    "\n",
    "And there's our physics function F(). If we want, we can expand it by element\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "F_{r_x}&=&0 \\\\\n",
    "F_{r_y}&=&0 \\\\\n",
    "F_{v_x}&=&-\\frac{\\mu r_x}{\\left(\\sqrt{r_x^2+r_y^2}\\right)^3} \\\\\n",
    "F_{v_y}&=&-\\frac{\\mu r_y}{\\left(\\sqrt{r_x^2+r_y^2}\\right)^3} \\\\\n",
    "\\end{eqnarray*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Our radar is able to measure the distance (only) from itself to the satellite. Therefore the measurement vector at any time is just this distance, only one component again. The station is located at $\\vec{m}=\\begin{bmatrix}m_x & m_y\\end{bmatrix}^T$, so the distance from the radar to the satellite is\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "g(\\vec{x})&=&\\left|\\vec{r}-\\vec{m}\\right| \\\\\n",
    "          &=&\\sqrt{(r_x-m_x)^2+(r_y-m_y)^2}\n",
    "\\end{eqnarray*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement Noise\n",
    "\n",
    " > Mathematicians think [the Gaussian distribution] is a law of nature and physicists are convinced it is a mathematical theorem.\n",
    " > -- Gabriel Lippman, from Grewal and Andrews p62\n",
    " \n",
    "Given a mean and covariance matrix, you can generate a random population that (approximately) fits it and you can draw ellipsoids of given standard deviation. Likewise, given a set of samples presumed to be drawn from a Gaussian distribution, you can determine the mean and covariance.\n",
    "\n",
    "Any Gaussian normal multivariate distribution of a random variable $\\vec{X}$ is described by a mean vector $\\bar{x}$ and a covariance matrix $\\M{P}$. The mean vector is exactly what it seems. The covariance matrix is a property of a random vector variable and is defined as:\n",
    "\n",
    "$$\\M{P}=\\operatorname E((\\vec{X}-\\bar{x})(\\vec{X}-\\bar{x})^T)$$\n",
    "\n",
    "The scalar variance is the square of the standard deviation and has units of the square of the units of the scalar variable. Likewise the covariance matrix is the \"square\" of what you might think of as the standard deviation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a sample set from a mean and covariance\n",
    "The following recipe is underived here.\n",
    "\n",
    "* Generate a sample set with the required number of vectors $N$ with the required number of components $m$, each a sample of a Gaussian normal scalar random variable with zero mean and variance 1. This will create a set of vectors with (approximately) zero vector mean and covariance equal to the $m \\times m$ identity matrix. We will consider this to be a matrix $\\M{X}$, where each sample is a column vector, therefore the matrix has size $m\\times N$.\n",
    "* Calculate the lower Cholesky decomposition of the covariance matrix $\\M{A}=\\operatorname{chol}(\\M{P})$.\n",
    "* You can check by verifying that $\\M{A}\\M{A}^T=\\M{P}$ to sufficient precision\n",
    "* Use the $\\M A$ matrix to transform the set of vectors, giving a set $\\M{Y}=\\M{A}\\M{X}$ with zero mean and the given covariance $\\M{P}$.\n",
    "* Add the mean vector $\\bar{x}$ to each column generating a new matrix $\\M{Z}$ such that $\\vec{Z}_{\\operatorname{column}i}=\\vec{Y}_{\\operatorname{column}i}+\\bar{x}$. This $\\M{Z}$ is the desired sample, with given mean $\\bar{x}$ and covariance about that mean $\\M{P}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import cholesky\n",
    "\n",
    "def pnoise(N,P,xbar=None):\n",
    "    m=P.shape[0]\n",
    "    X=nr.randn(m,N)\n",
    "    A=cholesky(P)\n",
    "    X=A@X\n",
    "    if xbar is not None:\n",
    "        X+=xbar\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing uncertainty ellipsoids \n",
    "Often it is educational to draw ellipsoids of one or more \"$n$-sigma\" surfaces. We can use the same matrix $\\M{A}$ from above. This time, the samples will not be taken at random, but will be a circle of radius $n$ and the required dimension. For instance, a 2-element vector random variable will require an $S_1$ (just a normal circle) in 2D space, a 3-element vector an $S_2$ circle (surface of a sphere) in 3D space, a 4-element vector is a $S_3$ (surface of a 4D hypersphere) in 4D space, and in general an $n$-element vector will require a set of samples of distance $n$ from the origin of $n$-space, or a unit-radius $S_{n-1}$.\n",
    "\n",
    "Code for the 2D case follows. Higher dimensions are harder simply because it is harder to evenly space points on the surface of a sphere or hypersphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pell(n,P,xbar=None):\n",
    "    q=np.arange(0,2*np.pi,0.01)\n",
    "    c=np.cos(q)\n",
    "    s=np.sin(q)\n",
    "    X=np.array([c,s])*n \n",
    "    A=cholesky(P)\n",
    "    X=A @ X\n",
    "    if xbar is not None:\n",
    "        X+=xbar\n",
    "    return X\n",
    "\n",
    "P=np.array([[3,3],[3,4]])\n",
    "xbar=np.array([[100],[-200]])\n",
    "x=pnoise(1000,P,xbar)\n",
    "e1=pell(1,P,xbar)\n",
    "e2=pell(2,P,xbar)\n",
    "e3=pell(3,P,xbar)\n",
    "plt.figure(\"Covariance\")\n",
    "plt.plot(x [0,:],x [1,:],'k.')\n",
    "plt.plot(e1[0,:],e1[1,:],'r-')\n",
    "plt.plot(e2[0,:],e2[1,:],'g-')\n",
    "plt.plot(e3[0,:],e3[1,:],'b-')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating covariance given a set of samples\n",
    "The mean is easy, it's just the total of all the vectors divided by the number of vectors\n",
    "\n",
    "The covariance is calculated as:\n",
    "\n",
    "$$\\M{P} = \\frac{1}{m-1}\\sum_{i=1}^m (\\vec{x}_i-\\bar{x})(\\vec{x}_i-\\bar{x})^T$$\n",
    "\n",
    "We are using $\\frac{1}{N-1}$ for the same reason we use it in a sample standard deviation -- there is one less degree of freedom due to the fact that we have to calculate the mean from the samples as well as the standard deviation.\n",
    "\n",
    "Alternatively, arranging the observation vectors as the columns of a matrix, so that\n",
    "\n",
    "$$\\M{X} = \\begin{bmatrix}\\vec{x}_1 & \\vec{x}_2 & \\dots & \\vec{x}_N \\end{bmatrix}$$\n",
    "\n",
    "which is a matrix of $m$ rows and $N$ columns. Then, the sample covariance matrix can be computed as\n",
    "\n",
    "$$\\M{P} = \\frac{1}{N-1}\\left( \\M{F} - \\bar{x}\\vec{1}^T \\right)\\left( \\M{F} - \\bar{x}\\vec{1}^T\\right)^T$$\n",
    "\n",
    "where $\\vec{1}$ is a column vector with all components 1. This is used to create an $m \\times N$ matrix where every column vector is $\\bar{x}$. In code we can say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcalc(X):\n",
    "    xbar=np.mean(X,1).reshape(-1,1)\n",
    "    Xac=X - xbar\n",
    "    N=Xac.shape[1]\n",
    "    P=(Xac @ Xac.T)/(N-1)\n",
    "    return (xbar,P)\n",
    "\n",
    "print(pcalc(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian matrices\n",
    "\n",
    "First, $\\M \\Phi$. This one has a lot of blank space because two of its components are simple variables, and the other two are functions of only two elements of the state vector, so right off we have:\n",
    "\n",
    "$$\n",
    "\\M \\Phi=\\begin{bmatrix}0 & 0 & 1 & 0 \\\\\n",
    "           0 & 0 & 0 & 1 \\\\\n",
    "           \\frac{dF_{v_x}}{dr_x} & \\frac{dF_{v_x}}{dr_y} & 0 & 0 \\\\\n",
    "           \\frac{dF_{v_y}}{dr_x} & \\frac{dF_{v_y}}{dr_y} & 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "Only six components out of 16 are nonzero, and only four are nontrivial. So, what about those?\n",
    "\n",
    "$$\n",
    "F_{v_x}=-\\frac{\\mu r_x}{\\left(\\sqrt{r_x^2+r_y^2}\\right)^3}\n",
    "$$\n",
    "\n",
    "To the derivinator! [derivative of mu*x/(sqrt(x^2+y^2))^3](http://www.wolframalpha.com/input/?i=derivative+of+mu*x%2F%28sqrt%28x%5E2%2By%5E2%29%29%5E3) I don't think that Alpha is smart enough to substitute r, so I just put it in explicitly, and we can sub it back out when we get the result. Alpha (now I want to call it \"Ziggy\" for some reason) says that the result is\n",
    "\n",
    "\n",
    "    (d)/(dx)((mu x)/sqrt(x^2+y^2)^3) = (mu (y^2-2 x^2))/(x^2+y^2)^(5/2)\n",
    "\n",
    "\n",
    "or cleaning up and putting back in $r=\\sqrt{r_x^2+r_y^2}$\n",
    "\n",
    "$$\n",
    "\\frac{dF_{v_x}}{dr_x}=-\\frac{\\mu(r_y^2-2r_x^2)}{r^5}\n",
    "$$\n",
    "\n",
    "\n",
    "We continue to get the other three elements:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\frac{dF_{v_x}}{dr_y}&=& -\\frac{\\mu(3r_x r_y)}{r^5} \\\\\n",
    "\\frac{dF_{v_y}}{dr_x}&=& -\\frac{\\mu(3r_x r_y)}{r^5} \\\\\n",
    "\\frac{dF_{v_y}}{dr_y}&=&-\\frac{\\mu(r_x^2-2r_y^2)}{r^5}\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Note that now that we have the power of Python and SymPy in our corner, we can do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from IPython.display import display\n",
    "#Symbolic form of physics equations, so that they can be symbolically differentiated\n",
    "rx,ry,vx,vy,mu=sympy.symbols('r_x r_y v_x v_y mu')\n",
    "r=sympy.sqrt(rx**2+ry**2)\n",
    "Frx=vx\n",
    "Fry=vy\n",
    "Fvx=-mu*rx/r**3\n",
    "Fvy=-mu*ry/r**3\n",
    "\n",
    "def fjac(xsyms,paramsyms,Fsyms):\n",
    "    \"\"\"\n",
    "    Create callable vector functions and Jacobian functions\n",
    "    from symbolic equations\n",
    "    :param xsyms    : Tuple or list of symbols for the names of each state vector component\n",
    "    :param paramsyms: Tuple or list of symbols for the names of each variable used which is not\n",
    "                      part of the state vector\n",
    "    :param Fsyms    : Tuple or list of symbolic expressions for each component of the vector formula.\n",
    "                      There must be a one-to-one correspondence between xsyms and Fsyms, and each\n",
    "                      component must use only variables in xsyms and paramsyms.\n",
    "    \"\"\"\n",
    "    xmat=sympy.Matrix(xsyms) #Note that these build column matrices out of 1D iterables\n",
    "    Fmat=sympy.Matrix(Fsyms)\n",
    "    dFdx=Fmat.jacobian(xmat)\n",
    "    dFdx=sympy.simplify(dFdx)\n",
    "    _F=sympy.lambdify(xsyms+paramsyms,Fmat)\n",
    "    help(_F)\n",
    "    def F(x,params):\n",
    "        \"\"\"\n",
    "        Physics function F(<x>). Takes a state vector, returns the derivative of\n",
    "        the state vector with respect to time. Primary physics model definition\n",
    "        \"\"\"\n",
    "        return _F(*(tuple(x.ravel())+tuple(params)))\n",
    "    print(\"State vector: \")\n",
    "    display(xmat)\n",
    "    print(\"Physics Function: \")\n",
    "    display(Fmat)\n",
    "    print(\"Physics Matrix: \")\n",
    "    display(dFdx)\n",
    "    _jac=sympy.lambdify(xsyms+paramsyms,dFdx)\n",
    "    def jac(x,params):\n",
    "        \"\"\"\n",
    "        Physics matrix [\\Phi(<x>)]. Takes a state vector, returns Jacobian of\n",
    "        the state vector. Secondary physics model definition\n",
    "        \"\"\"\n",
    "        return _jac(*(tuple(x.ravel())+tuple(params)))\n",
    "    return (F,jac)\n",
    "    \n",
    "(F_B612,Phi_B612)=fjac([rx,ry,vx,vy],[mu],[Frx,Fry,Fvx,Fvy])\n",
    "xh=np.array([[3],[5],[0],[0]])\n",
    "m=[1000]\n",
    "print(F_B612(xh,m))\n",
    "print(Phi_B612(xh,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for $\\M H$. This has four elements, one row for the one element of the observation by four columns for the elements of the state, but two of them are zero since the measurement doesn't involve the velocity elements of the state. We will define $\\rho$ (Greek small rho) as the measurement itself, so:\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\rho&=&g(\\vec{x}) \\\\\n",
    "    &=&\\sqrt{(r_x-m_x)^2+(r_y-m_y)^2}\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\frac{dg}{dr_x}&=&\\frac{r_x-m_x}{\\rho} \\\\\n",
    "\\frac{dg}{dr_y}&=&\\frac{r_y-m_y}{\\rho} \\\\\n",
    "\\end{eqnarray*}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx,my=sympy.symbols('m_x m_y')\n",
    "rho=sympy.sqrt((rx-mx)**2+(ry-my)**2)\n",
    "(g_B612,H_B612)=fjac([rx,ry,vx,vy],[mx,my],[rho])\n",
    "\n",
    "xh=np.array([[3],[5],[0],[0]])\n",
    "m=[0,1]\n",
    "print(\"g(<3,5,0,0>,<0,1>)=\",g_B612(xh,m))\n",
    "print(\"H(<3,5,0,0>,<0,1>)=\",H_B612(xh,m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked example\n",
    "\n",
    "We can hang this model on the same scaffold we built last time. Mostly we just change the model functions, but we are also going to change the simulator at the top, since this model is more complicated than last time.\n",
    "\n",
    "We are going to orbit planet [B612](http://en.wikipedia.org/wiki/46610_Besixdouze), a perfectly spherical, homogeneous, radar-transparent planet which has a radius of 10m but sufficient gravity to live on conveniently.  The planet has a surface gravity of about 1g, exactly 10m/s^2. \n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "a&=&\\frac{\\mu}{r^2} \\\\\n",
    "ar^2&=&\\mu \\\\\n",
    "\\end{eqnarray*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_B612=10 #m\n",
    "a0_B612=10 #m/s**2\n",
    "mu_B612=a0_B612*r_B612**2\n",
    "print(mu_B612)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In units of meters and seconds, it has $\\mu=1000$, which means that a ball thrown at 10m/s at the surface will stay in a circular orbit right at the surface, and circle the planet in 6.283 seconds.\n",
    "\n",
    "As an aside, B612 is one weird planet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=6.67430e-11 #Universal gravitational constant, m**3/kg/s**2, CODATA 2018 value\n",
    "M_B612=mu_B612/G\n",
    "print(\"M=%e kg\"%M_B612)\n",
    "V_B612=4/3*np.pi*r_B612**3\n",
    "rho_B612=M_B612/V_B612\n",
    "print(\"V=%f m**3\"%V_B612)\n",
    "print(\"(water=1000kg/m**3) rho=%e kg/m**3\"%rho_B612)\n",
    "\n",
    "rho_granite=2700 #kg/m**3\n",
    "comp=6\n",
    "print(9**comp)\n",
    "rho_granite_comp=rho_granite*(9**comp)\n",
    "print(\"%d times compressed=%e kg/m**3\"%(comp,rho_granite_comp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It needs to weigh almost 15 billion tons to exert this much gravity, and has a density of more than 3 million times that of water -- white dwarf degenerate matter is about 1 million times as dense as water. Sextuple compressed cobblestone is also about 1.4 million times as dense as water. And yet it's radar-transparent..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our program is pretty heavily modified here, so let's look at it fresh again. We use the physics and observation functions and Jacobians defined above, so most of what is below is driver code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first bit, we call a function called ``trueState()`` which we pass in the initial conditions, the timestamps we care about, and the physics function. It then does all the integrating and returns a list of true state vectors at all the requested times.\n",
    "\n",
    "Note that when we call this function, we pass it a function as a parameter, rather than evaluating the function and passing its result. Function ``trueState()`` will then call that function itself. In this way, we can use the same code to call our own model functions back, so the same framework can support any physics model. The same thing can be done in C with function pointers, in Java with interfaces, and in most truly useful languages in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trueState(t,xt0,F,Fpar,nstep=1000):\n",
    "    \"\"\"\n",
    "    Calculate the true trajectory, given the true initial condition and the physics function F\n",
    "    \"\"\"\n",
    "\n",
    "    xt=np.zeros((xt0.size,t.size)) #True state vector (to be calculated)\n",
    "    xt[:,0]=xt0.ravel()\n",
    "    #Do a numerical integrator to get the positions\n",
    "    for i in range(1,t.size):\n",
    "        xt_im1=xt[:,i-1].reshape(-1,1)  #Previous true state\n",
    "        xt_i=xt_im1       #Will contain current true state\n",
    "        dt=t[i]-t[i-1]\n",
    "        ddt=dt/nstep;         #Do substeps between measurements\n",
    "        for j in range(1,nstep):\n",
    "            #Just use our physics function - that's what it is there for.\n",
    "            xt_i=xt_i+ddt*F(xt_i,Fpar)\n",
    "        xt[:,i]=xt_i.ravel();\n",
    "    return xt\n",
    "\n",
    "t=np.arange(0,10,0.1)\n",
    "xt0=np.array([[11],[0],[0],[10]])\n",
    "xt=trueState(t=t,xt0=xt0,F=F_B612,Fpar=[1000])\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(\"True trajectory\")\n",
    "plt.plot(xt[0,:],xt[1,:])\n",
    "plt.plot(r_B612*np.sin(np.arange(0,6.28,0.01)),r_B612*np.cos(np.arange(0,6.28,0.01)),'k-')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call trueObs(), which takes a list of state vectors and the observation function, and produces a list of observations, with noise sprinkled on it if requested. In this case, we call it twice, once with noise and once without, so we can compare the Truth to our estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueObs(xt,g,gpar,R=None,seed=3217):\n",
    "    #Size the problem\n",
    "    s=xt.shape\n",
    "    n=s[0]\n",
    "    xt0=xt[:,0].reshape(-1,1)\n",
    "    z=np.zeros((g(xt0,m).size,s[1]))\n",
    "    #Clean observations\n",
    "    for i in range(s[1]):\n",
    "        z[:,i]=g(xt[:,i].reshape(n,1),gpar).ravel()\n",
    "  \n",
    "    #We want random noise, but the *same* random noise each time we run\n",
    "    if R is not None:\n",
    "        if seed is not None:\n",
    "            nr.randn(seed)\n",
    "        pn=pnoise(s[1],R) #Measurement noise\n",
    "        z=z+pn            #Noisy Observations\n",
    "    return z\n",
    "\n",
    "m=[10,0]\n",
    "zt=trueObs(xt,g_B612,m)\n",
    "R=np.array([[0.5**2]])\n",
    "zn=trueObs(xt,g_B612,m,R)\n",
    "plt.figure(\"Observations\")\n",
    "plt.plot(t,zt[0,:],'-')\n",
    "plt.plot(t,zn[0,:],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make one time/measurement update, call `ekf_step()`. If you get your measurements one at a time and don't care so much about history, perhaps because you are running a robot control loop, you can call ekf_step() directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekf_step(xh_im1, P_im1, z_i, dt, F, Fpar, g, gpar, Phi, H, Q, R):\n",
    "    \"\"\"\n",
    "    :param xh_im1: Previous estimate of the state vector\n",
    "    :param P_im1 : Previous estimate covariance\n",
    "    :param z_i   : current measurement vector\n",
    "    :param dt    : time between last and current measurement\n",
    "    :param F     : Physics function\n",
    "    :param Fpar  : Physics function\n",
    "    :param g     : Measurement function\n",
    "    :param gpar  : Measurement function\n",
    "    :param Phi   : Physics matrix\n",
    "    :param H     : Measurement matrix\n",
    "    :param Q     : Process noise covariance matrix, square n x n where n is number of elements of state vector\n",
    "    :param R     : Measurement noise covariance matrix, square m x m where m is number of elements of measurement vector\n",
    "    :return      : A tuple:\n",
    "        xh_i - New estimated state vector\n",
    "        P_i  - New estimate covariance matrix\n",
    "    \"\"\"\n",
    "    # One numerical integrator for both 1A and 1B, so that 1B can use the\n",
    "    # intermediate results of 1A.\n",
    "    xh_im = xh_im1  # To become updated state estimate <x^_i->\n",
    "    A = np.eye(P_im1.shape[0])  # The thing we integrate in 1b, will be come [A]\n",
    "    nstep = 1000\n",
    "    ddt = dt / nstep\n",
    "    for j in range(nstep):\n",
    "        # 1a. Use numerical integration to update state vector through time from\n",
    "        #    <x^_{i-1}> to <x^_i->\n",
    "        xh_im = xh_im + ddt * F(xh_im, Fpar)\n",
    "        # 1b. Use numerical integration to update [A]\n",
    "        A = A + ddt * (Phi(xh_im, Fpar) @ A)\n",
    "\n",
    "    # 1c, state deviation estimate\n",
    "    Xh_im = np.zeros(xh_im.shape)\n",
    "    # 2. Projected covariance estimate\n",
    "    P_im = A @ P_im1 @ A.T + Q\n",
    "    # 3a. Linearized observation matrix\n",
    "    H_i = H(xh_im, gpar)\n",
    "    # 3b. Kalman gain\n",
    "    K = P_im @ H_i.T @ _inv(H_i @ P_im @ H_i.T + R)\n",
    "    # 4a. Measurement deviation\n",
    "    Z_i = z_i - g(xh_im, gpar)\n",
    "    # 4b. Measurement update of state deviation\n",
    "    Xh_i = Xh_im + K @ (Z_i - H_i @ Xh_im)\n",
    "    # 4c. Update of reference state vector\n",
    "    xh_i = xh_im + Xh_i\n",
    "    # 5. Measurement update of state covariance\n",
    "    P_i = (np.eye(P_im.shape[0]) - K @ H_i) @ P_im\n",
    "    return (xh_i, P_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the initial guess and noise estimates, then call `ekf_loop()` to actually run the Extended Kalman filter. It takes a lot of parameters, but none of them are complicated. The hardest part is just passing them in the correct order. If you have a whole bunch of measurements in a block that you want to do, this is the way to go. This function calls `ekf_step()` to actually run the equations we have derived. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ekf_loop(xh_0, P_0, z, t, F, Fpar, g, gpar, Phi, H, Q, R):\n",
    "    \"\"\"\n",
    "\n",
    "    xh_0 - initial guess of the state vector\n",
    "    P_0 - initial guess of the estimate covariance\n",
    "    z - list of measurement vectors\n",
    "    t - array of times, same length as number of measurements\n",
    "    F - Name of physics function\n",
    "    g - Name of observation function\n",
    "    Phi - Name of Physics matrix function\n",
    "    H - Name of observation matrix function\n",
    "    Q - Process noise covariance matrix, square n x n where n is number of elements of state vector\n",
    "    R - Measurement noise covariance matrix, square m x m where m is number of elements of measurement vector\n",
    "\n",
    "    It produces the following outputs:\n",
    "\n",
    "    xh - list of estimated states\n",
    "    P - list of estimate covariance matrices\"\"\"\n",
    "    s = z.shape\n",
    "    print(s)\n",
    "    n = s[1]  # Number of observations\n",
    "    xh = np.zeros((xh_0.size, n))  # History of all estimates (starts as initial estimate)\n",
    "    xh[:, 0] = xh_0.ravel();\n",
    "    P = np.zeros((xh_0.size, xh_0.size, n))  # History of all estimate covariances\n",
    "    P[:, :, 0] = P_0;\n",
    "    for i in range(1, n):\n",
    "        # Pull previous estimate from histories\n",
    "        xh_im1 = xh[:, i - 1].reshape(-1, 1)  # Previous extimate <x^_{i-1}>\n",
    "        P_im1 = P[:, :, i - 1]  # Previous covariance <P^_{i-1}>\n",
    "        z_i = z[:, i].reshape(-1, 1)\n",
    "        dt = t[i] - t[i - 1]\n",
    "        [xh_i, P_i] = ekf_step(xh_im1, P_im1, z_i, dt, F, Fpar, g, gpar, Phi, H, Q, R)\n",
    "\n",
    "        # Record the current estimates\n",
    "        xh[:, i] = xh_i.ravel();\n",
    "        P[:, :, i] = P_i;\n",
    "    return (xh, P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last part is the driver, and as we can see, most of the code has been farmed out to various subfunctions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_B612(Q,R,t1=20,tag=\"\"):\n",
    "    # Simulated actual trajectory. Unperturbed orbit around B612 at slightly\n",
    "    # higher than circlular velocity.\n",
    "\n",
    "    t = np.arange(0, t1, 0.1)  # Timestamp of each measurement\n",
    "    xt0 = np.array([[11], [0], [0], [10]])  # Position <11,0> meters from center, velocity <0,10>\n",
    "    mu = [1000]\n",
    "    xt = trueState(t, xt0, F_B612, mu)\n",
    "\n",
    "    m = [10, 0]\n",
    "    zt = trueObs(xt, g_B612, m)\n",
    "    z = trueObs(xt, g_B612, m, R)\n",
    "    #z=zt #Give it perfect measurements, so there should be zero residual\n",
    "    xh_0 = np.array([[12], [0], [0], [9]])  # Initial state vector guess, slightly wrong\n",
    "    #xh_0=xt0 #Give it a perfect initial estimate\n",
    "\n",
    "    P_0 = np.diag([1, 1, 1, 1])  # Initial state vector uncertainty, 1m in position and 1m/s in velocity\n",
    "\n",
    "    [xh, P] = ekf_loop(xh_0, P_0, z, t, F_B612, mu, g_B612, m, Phi_B612, H_B612, Q, R)\n",
    "\n",
    "    # Plot some interesting results\n",
    "    plt.figure(\"Nonlinear trajectory\"+tag)\n",
    "    plt.plot(10 * np.cos(np.arange(0, 2 * np.pi, 0.01)), 10 * np.sin(np.arange(0, 2 * np.pi, 0.01)), 'k-',label='Planet B612 surface')\n",
    "    plt.plot(xt[0, :], xt[1, :], 'r+-',label='True position')\n",
    "    plt.plot(xh[0, :], xh[1, :], 'b+',label='Estimated position')\n",
    "    plt.legend()\n",
    "    plt.axis('equal')\n",
    "\n",
    "    # measurement residual plot\n",
    "    zh = trueObs(xh, g_B612, m);\n",
    "    plt.figure(\"Nonlinear measurements\"+tag)\n",
    "    plt.plot(t, zt[0,:], 'r-',label='Actual radar distance')\n",
    "    plt.plot(t, zh[0,:], 'b-',label='Radar distance from estimate');\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure(\"Nonlinear residuals\"+tag)\n",
    "    plt.plot(t, zt[0,:]-zh[0,:],'+', label='residuals')\n",
    "    plt.plot(t, t*0, 'k-',label='residual=0');\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # legend(,);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we did. First, use 10cm noise and a nonphysical Q with 10cm noise on velocity per step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q = np.diag([0, 0, 0.01, 0.01])  # Non-physical process noise covariance\n",
    "R = np.array([[0.1 ** 2]])  # Measurement noise covariance\n",
    "nonlinear_B612(Q,R,t1=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting. The filter is satisfied it did a good job -- the estimated trajectory has residuals well within the expected range, given the amount of noise we put on the measurements. However, it does this by taking advantage of the process noise to fudge the trajectory around quite a bit. Since there is no real process noise in this case, let's try with a zero $\\M Q$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.diag([0, 0, 0, 0])  # Process noise covariance, 0 position and 10cm/s^2 on velocity\n",
    "nonlinear_B612(Q,R,t1=10,tag=\" zero Q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a rough start, and never really settles in well. Maybe the initial estimate is just too far off. In any case, I think one thing going on here is that the measurement we have doesn't constrain the orbit, IE the state isn't observable from this measurement type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
