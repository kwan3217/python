{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flock Filter\n",
    "\n",
    "## Drawbacks of UKF\n",
    "\n",
    "$$\n",
    "\\def\\M#1{{[\\mathbf{#1}]}}\n",
    "\\def\\MM#1#2{{[\\mathbf{#1}{#2}]}}\n",
    "\\def\\E{\\operatorname{E}}\n",
    "\\def\\cov{\\operatorname{cov}}\n",
    "\\def\\T{^\\mathsf{T}}\n",
    "$$\n",
    "\n",
    "The [unscented Kalman filter](UnscentedKalman.ipynb) is an attempt to preserve non-Gaussian covariances through non-linear transformations, but if there are frequent measurements, then the covariance gets Gaussianized (by way of the unscented transform) anyway, very often. The unscented transform builds its sigma points based on an assumption of Gaussian distribtion, pushes the sigma points through the nonlinear function to get a non-Gaussian point cloud, but then immediately calculates a Gaussian approximation (in the form of a mean and covariance) *and throws away the sigma points*. Each time, the sigma points are constructed anew. For one, this seems wasteful, since you have to do a Cholesky decomposition of the covariance matrix at each measurement. For another, it means that the problem is re-Gaussianized at each measurement. \n",
    "\n",
    "The case I am thinking of is the hyperbolic orbit, right near periapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run UnscentedKalman.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dynamics\n",
    "rx,ry,vx,vy=sympy.symbols('r_x r_y v_x v_y')\n",
    "#It's OK to introduce intermediate symbols, since they are still defined in terms\n",
    "#of the symbols we will be using in the state vector\n",
    "r=sympy.sqrt(rx**2+ry**2) \n",
    "Frx=vx\n",
    "Fry=vy\n",
    "Fvx=-rx/r**3\n",
    "Fvy=-ry/r**3\n",
    "(F,_)=fjac([rx,ry,vx,vy],[],[Frx,Fry,Fvx,Fvy]) #Don't care about physics matrix\n",
    "\n",
    "#Measurement equations\n",
    "mx=2\n",
    "my=0\n",
    "rho=sympy.sqrt((rx-mx)**2+(ry-my)**2)\n",
    "theta=sympy.atan2(ry-my,-(rx-mx)) #Put the branch cut on the x-axis, so that the test orbit doesn't cross it\n",
    "(g,_)=fjac([rx,ry,vx,vy],[],[rho,theta]) #Don't care about measurement matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cloud=1000 #Number of elements in the point cloud\n",
    "t0=0\n",
    "t1=20\n",
    "dt=0.1\n",
    "ts=np.arange(t0,t1,dt) #Time series\n",
    "n_t=ts.size\n",
    "\n",
    "Q = np.diag([0.0, 0.0, 0.0, 0.0])  # Non-physical process noise covariance\n",
    "R = np.diag([0.1 ** 2,0.01**2])  # Measurement noise covariance\n",
    "\n",
    "x0=np.array([[8],[2],[-0.5],[0]])\n",
    "P0=np.diag([0.01,0.01,1e-5,1e-5])\n",
    "\n",
    "#Monte Carlo initial conditions\n",
    "nr.seed(3217)\n",
    "xm = pnoise(n_cloud, P0, x0)\n",
    "\n",
    "#EKF initial conditions\n",
    "xe=x0*1\n",
    "Pe=P0*1\n",
    "\n",
    "#UKF initial conditions\n",
    "(xu, W) = sigma(x0, P0)\n",
    "\n",
    "plt.figure(\"Non-Gaussian point cloud\")\n",
    "plt.plot([0], [0], 'kx')\n",
    "dt=ts[1]-ts[0]\n",
    "for i, t in enumerate(ts):\n",
    "    #Do all of the plotting\n",
    "    if i % 20 == 0 or i+1==len(ts):\n",
    "        if i+1==len(ts) or i==120:\n",
    "            plt.plot(xm[0, :], xm[1, :], 'r+',label=\"Monte Carlo point cloud\")\n",
    "            plt.plot(xtm[i,0,:],xtm[i,1,:],'y+',label=\"Kepler point cloud\")\n",
    "        (xmbar, Pm) = pcalc(xm)\n",
    "        (cm, sm) = pell(3, Pm[0:2,0:2], xmbar[0:2])\n",
    "        plt.plot(cm, sm, 'r-',label='Monte Carlo' if i==0 else None)\n",
    "\n",
    "        if i+1==len(ts):\n",
    "            plt.plot(xe[0, :], xe[1, :], 'bo',label=\"EKF estimate\")\n",
    "        (ce, se) = pell(3, Pe[0:2,0:2], xe[0:2])\n",
    "        plt.plot(ce, se, 'b-',label='Linearized' if i==0 else None)\n",
    "\n",
    "        if i+1==len(ts):\n",
    "            plt.plot(xu[0, :], xu[1, :], 'g+',label=\"Sigma point cloud\")\n",
    "        (xubar, Pu) = sigmainv(xu, W)\n",
    "        (cu, su) = pell(3, Pu[0:2,0:2], xubar[0:2])\n",
    "        plt.plot(cu, su, 'g-',label='Unscented' if i==0 else None)\n",
    "    #Actually step the integrators\n",
    "    xm = rk4(Fnl, dt, xm, [], nstep=nstep,t0=t)\n",
    "    xu = rk4(Fnl, dt, xu, [], nstep=nstep,t0=t)\n",
    "    (xe, Pe) = ekf_timeup(xh_im1=xe, P_im1=Pe, t=t, dt=dt, F=Fnl, Phi=Phinl, Fpar=[],nstep=nstep)\n",
    "plt.axis('equal')\n",
    "plt.xlim([-1,1])\n",
    "plt.ylim([-1.3,1.3])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, the point cloud isn't really that well-described by any ellipse. Sure, the Monte Carlo and Unscented ellipses cover the covariance, but the covariance is only really enough information if the point cloud is Gaussian. Imagine a long unscented transform from the initial condition, where the distribution really is Gaussian. If we take a measurement right at periapse, the point cloud will have its mean and covariance computed, Kalman gain applied, and from then forward, the distribution will be re-Gaussianized. Imagine that the measurement didn't help much, and that the covariance after is the same as the one before. In this case, the next point cloud will be Gaussian-distributed over the green ellipse. This will put some points *much* closer to the origin, which will fling them pretty far afield from the center.\n",
    "\n",
    "This drawback applies equally to the Monte Carlo filter, with it's near-infinite point cloud, and the unscented filter, with its finite set of sigma points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flock Filter\n",
    "\n",
    "This is designed for *either* the Monte Carlo *or* the unscented point clouds. Instead of jumping back and forth between problem domains, we will do our best to keep it in one domain -- that of the point clouds. Especially in our case, the transformation from covariance to point cloud requires a Cholesky decomposition, which among other problems, I don't have code for that on my bare-metal embedded system. So what we will do is:\n",
    "\n",
    "1. Transform the input mean and covariance into a point cloud *once*, and keep track of the weight $W_j$. For sigma points, use ``sigma()``. For Monte Carlo, use ``perror()``, and each weight is $W_j=\\frac{1}{1-N}$ where $N$ is the number of points in the cloud.\n",
    "2. For each measurement:\n",
    "   * Propagate the points using the nonlinear transform to the time of the measurement: $$\\vec{x}^-_j=\\vec{f}(\\vec{x}_{j,i-1},\\vec{k},t)$$\n",
    "   * Figure $\\M \\Gamma$  from the point cloud, just like in the unscented transform:$$\n",
    "   \\begin{align}\n",
    "   \\vec{z}_j=&\\vec{g}(\\vec{x}^-_j,\\vec{k},t) \\\\\n",
    "   \\hat{\\vec{z}}=&\\sum_{j}W_j \\hat{\\vec{z}}_j \\\\\n",
    "\\M{\\Gamma}=&\\M{R}+\\sum_{j}W_j \\left\\{\\hat{\\vec{z}}-\\hat{\\vec{z}}_j\\right\\}\\left\\{\\hat{\\vec{z}}-\\hat{\\vec{z}}_j\\right\\}\\T\\end{align}$$\n",
    "   \n",
    "   * Figure $\\M S$ from the point cloud measurement residuals, just like in the unscented transform:\n",
    "   $$\\M{S}=\\sum_{j}W_j \\left\\{\\vec{x}^--\\vec{x}^-_j\\right\\}\\left\\{\\hat{z}-\\hat{z}_j\\right\\}\\T$$\n",
    "   * Figure $\\M K=\\M S\\M \\Gamma^{-1}$ just like everywhere else\n",
    "   * For *each point in the cloud*:\n",
    "     * calculate the correction by multiplying $\\M K$ by the measurement residual *for that point*: \n",
    "     $$\\begin{align}\n",
    "     \\vec{y}_j=&\\vec{z}-\\vec{z}_j \\\\\n",
    "     \\vec{x}_j=&\\vec{x}^-_j+\\M{K}\\vec{y}_j\n",
    "     \\end{align}$$\n",
    "\n",
    "The idea is that we repeatedly go from the point cloud domain to the covariance domain, but only to calculate the Kalman gain. We then use that gain in the point cloud domain. The covariances are made fresh from the cloud at each time it is needed, but the cloud is never again made from the covariance.\n",
    "\n",
    "We call it a *flock* filter because while the natural disposition of a cloud is to disperse, the measurement corrections applied via $\\M K$ cause each point to converge on the correct answer, like a flock of birds will converge on their formation because each bird corrects itself.\n",
    "\n",
    "The idea that makes this work is that the derivation of $\\M K$ does not depend on the actual state or measurement, so it must be able to guide corrections to points anywhere in a cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flock_measup(x_mj, W, z, g,gpar, R, t=None):\n",
    "    \"\"\"\n",
    "    :param x_mj  : Time-updated point cloud (at current time but before taking into account current measurement)\n",
    "    :param W     : Weights of sigma points\n",
    "    :param z     : current measurement vector\n",
    "    :param g     : Measurement function\n",
    "    :param gpar  : Extra parameters to pass to measurement function\n",
    "    :param R     : Measurement noise covariance matrix, square m x m where m is number of elements of measurement vector\n",
    "    :return      : A tuple:\n",
    "        x - Measurement-update point cloud\n",
    "    \"\"\"\n",
    "    def _inv(x):\n",
    "        \"\"\"\n",
    "        Matrix inverse which also handles scalars properly\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from scipy.linalg import inv\n",
    "            return inv(x)\n",
    "        except ValueError:\n",
    "            return np.array([[1.0/x]])\n",
    "    # Figure Gamma matrix from point cloud \n",
    "    z_j=g(x_mj,gpar,t)\n",
    "    (zh,Gamma)=sigmainv(z_j,W)\n",
    "    Gamma+=R\n",
    "    # Figure S matrix from point cloud measurement residuals\n",
    "    (xh_m,_)=sigmainv(x_mj,W)\n",
    "    dx=(xh_m-x_mj[:,0].reshape(-1,1))\n",
    "    dz=(zh  -z_j [:,0].reshape(-1,1))\n",
    "    dxdz=dx @ dz.T\n",
    "    S=W[0]*dxdz\n",
    "    for j in range(1,W.size):\n",
    "        S+=W[j]*(xh_m-x_mj[:,j].reshape(-1,1))@((zh-z_j[:,j].reshape(-1,1)).T)\n",
    "    # 5. Calculate the Kalman gain\n",
    "    K=S @ _inv(Gamma)\n",
    "    x_j=x_mj.copy()\n",
    "    for j in range(W.size):\n",
    "        # 6. Update each point in the cloud\n",
    "        y_j=z-z_j[:,j].reshape(-1,1)\n",
    "        x_j[:,j]=(x_mj[:,j].reshape(-1,1)+K@y_j).ravel()\n",
    "    return x_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there isn't any way to deal with $\\M Q$ this way -- it needs to be dealt with during the time update. With a linear or extended Kalman filter, process noise is added by just adding it to the time-updated state covariance. With an un-augmented unscented filter, we add the process noise to the state covariance that we recover from the sigma points. With the augmented unscented filter, the extra sigma points related to process noise are used, except this only works for the first step.\n",
    "\n",
    "There are a couple of ways to deal with this:\n",
    "\n",
    "0. Don't use process noise. This is fine for problems like orbital mechanics where you really do know all of the dynamics, but useless for things like the rocketometer problem.\n",
    "1. For augmented sigma points, I think what you have to do is to keep track of which points in the point cloud are there because of process noise. Before each time propagation step, add perturbations to the augmented points, based on the current $\\M Q$. If $\\M Q$ is constant, then you can just calculate these perturbations once, and add them each time. The justification for adding this each step is that this *is* what you get if you repeatedly time-update a linear or EKF filter without measurement updates. The measurement update will correct the points back inward towards the correct value.\n",
    "2. For unaugmented sigma points or Monte Carlo point clouds, create a random perturbation vector for each point, where the perturbations have zero mean and a covariance of $\\M Q$. I think that if $\\M Q$ is constant, you can create one random perturbation first, and add it at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flock_timeup(x_im1, t_im1, dt, F, Fpar=None, Qperturb=None, odesolve=rk4, nstep=10):\n",
    "    \"\"\"\n",
    "    Do the flock filter time update. Given a previous state estimate in the form of a point cloud, \n",
    "    and everything else needed to do the physics, calculate the updated state estimate point cloud\n",
    "    after taking a time step.\n",
    "    :param x_im1 : Previous point cloud, stack of N n-element vectors, or n x N matrix\n",
    "    :param t_im1 : initial time (time of previous measurement)\n",
    "    :param dt    : time between last and current measurement\n",
    "    :param F     : Physics function\n",
    "    :param Fpar  : Extra parameters to pass to physics functions\n",
    "    :param Qperturb: Process noise perturbation vectors. Stack of L n-element vectors, or n x L matrix.\n",
    "                     Will be used to perturb last last L points in the cloud. If L==N, then all\n",
    "                     vectors will be perturbed (method 2 above). If L<N, assume the last L vectors\n",
    "                     are the augmented sigma points (method 1 above). If not passed, don't use process noise\n",
    "                     (method 0 above).\n",
    "    :return      : A tuple:\n",
    "        xh_m - Time-updated point cloud\n",
    "    \"\"\"\n",
    "    if dt!=0:\n",
    "        xh_m=odesolve(F,dt,x_im1,k=Fpar,nstep=nstep,t0=t_im1)\n",
    "    else:\n",
    "        xh_m=x_im1.copy()\n",
    "    if Qperturb is not None:\n",
    "        L=Qperturb.shape[1]\n",
    "        xh_m[:,-L:]+=Qperturb\n",
    "    return xh_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flock_step(x_im1, W, z, dt, F, Fpar, g, gpar, Qperturb, R, odesolve=rk4, nstep=10, t=None):\n",
    "    \"\"\"\n",
    "    Call both the EKF time update and measurement update functions to process one measurement.\n",
    "    :param xh_im1: Previous estimate of the state vector\n",
    "    :param P_im1 : Previous estimate covariance\n",
    "    :param z_i   : current measurement vector\n",
    "    :param dt    : time between last and current measurement\n",
    "    :param F     : Physics function\n",
    "    :param Fpar  : Extra parameters to pass to physics function\n",
    "    :param g     : Measurement function\n",
    "    :param gpar  : Extra parameters to pass to measurement function\n",
    "    :param Q     : Process noise covariance matrix, square n x n where n is number of elements of state vector\n",
    "    :param R     : Measurement noise covariance matrix, square m x m where m is number of elements of measurement vector\n",
    "    :param odesolve: ODE solver to use, passed along to time update\n",
    "    :param nstep : Number of substeps to use in the step, passed along to time update\n",
    "    :return      : A tuple:\n",
    "        xh_i - New estimated state vector\n",
    "        P_i  - New estimate covariance matrix\n",
    "    \"\"\"\n",
    "    x_mj=flock_timeup(x_im1=x_im1, t_im1=t-dt, dt=dt, F=F, Fpar=Fpar, Qperturb=Qperturb)\n",
    "    return flock_measup(x_mj=x_mj, W=W, z=z, g=g, gpar=gpar, R=R, t=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flock_loop2(x_0,W, t,z,F,Fpar,g,gpar,Q,R):\n",
    "    N=x_0.shape[1]\n",
    "    if Q is not None:\n",
    "        Qperturb=pnoise(N,Q)\n",
    "    else:\n",
    "        Qperturb=None\n",
    "    #Indexes will be [time,vector component,point cloud index]\n",
    "    x_j=np.zeros((t.size,)+x_0.shape)\n",
    "    x_j[0,:,:]=x_0\n",
    "    xh=np.zeros((x_0.shape[0],t.size))\n",
    "    P=np.zeros((t.size,x_0.shape[0],x_0.shape[0]))\n",
    "    xh_i,P_i=sigmainv(x_0,W)\n",
    "    xh[:,0]=xh_i.ravel()\n",
    "    P[0,:,:]=P_i\n",
    "    for i in range(1,ts.size):\n",
    "        x_j[i,:,:]=flock_step(x_im1=x_j[i-1,:,:],W=W,\n",
    "                              z=z[:,i].reshape(-1,1),\n",
    "                              dt=t[i]-t[i-1],t=t[i],\n",
    "                              F=F,Fpar=Fpar,g=g,gpar=gpar,\n",
    "                              Qperturb=Qperturb,R=R)\n",
    "        xh_i,P_i=sigmainv(x_j[i,:,:],W)\n",
    "        xh[:,i]=xh_i.ravel()\n",
    "        P[i,:,:]=P_i\n",
    "    return xh,P,x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueState(t,xt0):\n",
    "    \"\"\"\n",
    "    Calculate the true trajectory, given the true initial condition and the physics function F\n",
    "    \"\"\"\n",
    "    return kepler(xt0,None,t)\n",
    "\n",
    "xt=trueState(t=ts,xt0=x0)\n",
    "\n",
    "plt.figure(\"Flock True trajectory\")\n",
    "plt.plot(xt[0,:],xt[1,:],label='true trajectory')\n",
    "plt.plot(0,0,'k+',label='center')\n",
    "plt.plot(mx,my,'r+',label='station')\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueObs(xt,g,R=None,seed=3218):\n",
    "    #Size the problem\n",
    "    s=xt.shape\n",
    "    n=s[0]\n",
    "    xt0=xt[:,0].reshape(-1,1)\n",
    "    z=np.zeros((g(xt0,None,None).size,s[1]))\n",
    "    #Clean observations\n",
    "    for i in range(s[1]):\n",
    "        z[:,i]=g(xt[:,i].reshape(n,1),None,None).ravel()\n",
    "  \n",
    "    if R is not None:\n",
    "        if seed is not None:\n",
    "            #We want random noise, but the *same* random noise each time we run\n",
    "            nr.randn(seed)\n",
    "        pn=pnoise(s[1],R) #Measurement noise\n",
    "        z=z+pn            #Noisy Observations\n",
    "    return z\n",
    "\n",
    "zt=trueObs(xt,gnl)\n",
    "zn=trueObs(xt,gnl,R)\n",
    "plt.figure(\"Flock range Observations\")\n",
    "plt.plot(ts,zt[0,:],'-')\n",
    "plt.plot(ts,zn[0,:],'.')\n",
    "plt.figure(\"Flock azimuth Observations\")\n",
    "plt.plot(ts,zt[1,:],'-')\n",
    "plt.plot(ts,zn[1,:],'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial condition error\n",
    "dx0=np.array([[0.1],[0.1],[0.1],[0.1]])\n",
    "\n",
    "#Point cloud\n",
    "nr.rand(3217)\n",
    "xm=pnoise(n_cloud, P0, x0+dx0)\n",
    "Wm=np.zeros(n_cloud,)+1/(n_cloud-1)\n",
    "nr.randn(3219)\n",
    "#Qperturbm=pnoise(n_cloud,Q)\n",
    "#Unaugmented sigma points\n",
    "(xu,Wu)=sigma(x0+dx0,P0)\n",
    "nr.randn(3220)\n",
    "#Qperturbu=pnoise(xu.shape[1],Q)\n",
    "\n",
    "%time (xh_m,P_m,x_m)=flock_loop2(xm, Wm,ts,zn,F,[],g,[],Q=None,R=R)\n",
    "print(xh_m.shape,P_m.shape,x_m.shape)\n",
    "%time (xh_u,P_u,x_u)=flock_loop2(xu, Wu,ts,zn,F,[],g,[],Q=None,R=R)\n",
    "print(xh_u.shape,P_u.shape,x_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Flock MC solution\")\n",
    "plt.plot(0,0,'k+')\n",
    "plt.plot(xt  [0,:],xt  [1,:],'r+-',label='True')\n",
    "plt.plot(xh_m[0,:],xh_m[1,:],'g+',label='MC mean')\n",
    "plt.plot(xh_u[0,:],xh_u[1,:],'b+',label='sigma mean')\n",
    "for i in range(0,ts.size):\n",
    "    (cm, sm) = pell(3, P_m[i,0:2,0:2], xh_m[0:2,i].reshape(-1,1))\n",
    "    plt.plot(cm, sm, 'g-',label='MC cov' if i==0 else None)\n",
    "    (cu, su) = pell(3, P_u[i,0:2,0:2], xh_u[0:2,i].reshape(-1,1))\n",
    "    plt.plot(cu, su, 'b-',label='Sigma cov' if i==0 else None)\n",
    "    if i<3:\n",
    "        plt.plot(x_m[i,0,:],x_m[i,1,:],'g*',label='MC points' if i==0 else None)\n",
    "        plt.plot(x_u[i,0,:],x_u[i,1,:],'b*',label='sigma points' if i==0 else None)\n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "\n",
    "zh_m=trueObs(xh_m,g)\n",
    "zh_u=trueObs(xh_u,g)\n",
    "\n",
    "plt.figure(\"Flock range measurements\")\n",
    "plt.plot(ts, zt[0,:], 'r-',label='Actual')\n",
    "plt.plot(ts, zh_m[0,:], 'g+',label='MC');\n",
    "plt.plot(ts, zh_u[0,:], 'b+',label='Sigma');\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(\"Flock range residuals\")\n",
    "plt.plot(ts, zt[0,:]-zh_m[0,:],'g+', label='MC residuals')\n",
    "plt.plot(ts, zt[0,:]-zh_u[0,:],'b+', label='Sigma residuals')\n",
    "plt.plot(ts, zt[0,:]-zn  [0,:],'r+', label='measurement noise')\n",
    "plt.plot(ts, ts*0, 'k-',label='residual=0');\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(\"Flock azimuth measurements\")\n",
    "plt.plot(ts, zt  [1,:], 'r-',label='Actual')\n",
    "plt.plot(ts, zh_m[1,:], 'g+',label='MC');\n",
    "plt.plot(ts, zh_u[1,:], 'b+',label='Sigma');\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(\"Flock azimuth residuals\")\n",
    "plt.plot(ts, zt[1,:]-zh_m[1,:],'g+', label='MC residuals')\n",
    "plt.plot(ts, zt[1,:]-zh_u[1,:],'b+', label='Sigma residuals')\n",
    "plt.plot(ts, zt[1,:]-zn  [1,:],'r+', label='measurement noise')\n",
    "plt.plot(ts, ts*0, 'k-',label='residual=0');\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
